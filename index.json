[{"content":"EKS Security Monitoring: Visibility, Runtime Detection \u0026amp; Best Practices Monitoring Kubernetes on AWS (EKS) brings challenges beyond traditional EC2 or IAM setups — pods, containers, control plane, node behavior, runtime threats — all need attention. This guide walks you through what to monitor, which tools matter, and how to build a monitoring strategy for EKS that balances depth, cost, and security.\nTable of Contents What Makes EKS Monitoring Special Types of Monitoring in EKS AWS-Native Monitoring Tools for EKS Runtime Security \u0026amp; Threat Detection Building an EKS Monitoring Pipeline: Architecture Example Best Practices \u0026amp; Common Pitfalls Conclusion 1. What Makes EKS Monitoring Special Dynamic infrastructure: Pods are ephemeral; nodes may scale up/down; containers restart; workloads shift. Multi-layered architecture: You have the cluster control plane, worker nodes, container runtime, networking, storage. Shared responsibility \u0026amp; visibility gaps: AWS manages the control plane, but worker nodes, pod configuration, and runtime monitoring are your responsibility. Volume \u0026amp; noise: Logs from kubelet, CNI plugins, app pods, etc. Filtering and prioritization are critical. 2. Types of Monitoring in EKS Monitoring Type What It Covers Why It Matters Infrastructure / Control Plane API server logs, audit events, scheduler, node health Detect cluster-level issues, privilege abuse Application / Pod-level Container logs, resource usage, restarts, failures Catch misbehaving containers and app issues Security / Runtime Events RBAC changes, kubectl exec, privilege escalation, filesystem/network anomalies Detect attacks or insider threats Network \u0026amp; Storage Pod-to-pod, ingress/egress, storage latency/errors Spot misconfigurations, data leakage Observability \u0026amp; Alerts Dashboards, alerts, traces Help with debugging and SLA adherence 3. AWS-Native Monitoring Tools for EKS CloudWatch Container Insights → Cluster, node, pod-level metrics. CloudWatch Logs + Fluent Bit → Collect stdout/stderr from pods, node system logs, kubelet/kube-proxy. EKS Control Plane Logging → API server, audit, authenticator, scheduler logs. CloudWatch Observability Operator → Simplifies metrics and dashboards. Amazon Managed Service for Prometheus + Grafana → PromQL queries and custom visualization without managing infra. AWS X-Ray \u0026amp; OpenTelemetry → Distributed tracing for microservices. AWS Security Hub Integration → Centralize findings and alerts from multiple sources. 4. Runtime Security \u0026amp; Threat Detection Falco + Plugins\nDetects anomalies in container behavior and Kubernetes API events. The k8saudit-eks plugin monitors audit logs for high-risk actions (kubectl exec, RBAC changes, etc.). Audit Logs\nEnable audit logging for EKS. Monitor high-value events: role bindings, service account creation, privileged pods. Custom Rules \u0026amp; Baselines\nDefine what “normal” looks like for your cluster. Alert when workloads deviate (e.g., images pulled from unknown registries, privileged pods). 5. Building an EKS Monitoring Pipeline: Architecture Example Here’s a sample end-to-end architecture you could adopt. You can scale or trim depending on cluster size, security posture, cost tolerance.\nArchitecture Overview Enable control plane logging to CloudWatch. Deploy Fluent Bit DaemonSet for node and pod logs. Use Container Insights or Prometheus for metrics. Deploy Falco with custom runtime rules. Forward Falco alerts via Fluent Bit → CloudWatch Logs. Transform alerts to AWS Security Finding Format (ASFF) → ingest into Security Hub. Route high-severity alerts to Slack, email, or PagerDuty. Sample Steps \u0026amp; Considerations Step Description Enable control plane audit \u0026amp; other logs Via EKS console or IaC, enable control plane logs: API server, authenticator, etc. Ensure they’re sent to CloudWatch. Deploy Fluent Bit (DaemonSet) On all worker node groups, configure it to collect pod logs (stdout/stderr), system logs, kubelets, etc. Apply filters to drop low-value logs (e.g. verbose debug). Deploy Container Insights Use the Container Insights add-on or Observability Operator. Ensure metrics from nodes \u0026amp; pods are collected. Deploy Falco via Helm With custom rule files, mounting audit log streams if applicable. Use Kubernetes service account with right IAM permissions. Set up Security Hub / Alert Routing Use AWS Lambda or built-in integrations. Determine severity, which alerts to send to DevSecOps / ops. Possibly automate remediation for highest-severity findings. Dashboard \u0026amp; Visualization Use Grafana (managed or self-hosted) for internal dashboards. Use CloudWatch dashboards for quick overviews. Cost / Performance Considerations More logging = more cost. Logs from control plane + audit + Application - stdout + Falco = high volume. Drop / sample / filter early. Retention: Hot vs cold. Archive older logs. Number of rules: Falco / audit rules too permissive → noise. Too many alerts → alert fatigue. Resource usage: Falco + Fluent Bit consume CPU / memory; choose node sizes accordingly or isolate in separate node group. 6. Best Practices \u0026amp; Common Pitfalls Enable only relevant control plane log types: too many logs create noise and costs. Structured logging: use JSON or other structured formats so that filtering / dashboards work well. Use IAM Roles for Service Accounts (IRSA) for log agents and detection tools to limit permissions. Filter / Sample / Drop unneeded logs: e.g. drop very verbose events in production. Baseline then alert on anomalies rather than static thresholds only. Keep Falco / detection rules up to date: attack tactics evolve. Monitor the monitor itself: are your agents failing? Are logs being ingested? Are metrics stale? Set up alert routing and priority: not every event needs paging; group, suppress, alert levels. 7. Conclusion EKS adds complexity to AWS monitoring in the form of ephemeral pods, runtime threats, and audit visibility gaps. But by layering AWS-native tools (CloudWatch, GuardDuty, Security Hub) with open-source detection (Falco, Prometheus, Grafana), you can cover infrastructure, runtime, and security monitoring in a practical way.\nEKS security monitoring is not about logging everything, it’s about collecting the right signals, prioritizing them, and making alerts actionable. Done right, you gain visibility, catch misconfigurations early, and detect threats before they escalate.\nIf this guide helped, share it with your team or subscribe to The Hidden Port for more AWS and cloud security deep-dives.\n","permalink":"https://thehiddenport.dev/posts/eks-security-monitoring/","summary":"Amazon EKS introduces new monitoring challenges: pods, containers, audit logs, runtime threats. This guide covers AWS-native monitoring tools, open-source Falco integration, and best practices to secure Kubernetes workloads.","title":"EKS Security Monitoring: Visibility, Runtime Detection \u0026 Best Practices"},{"content":"For the past years, most of my focus has been on cloud security — hardening AWS environments, responding to incidents, and making sure access is tightly controlled. But lately, I’ve felt the urge to explore a different side of the equation: ethical hacking.\nThat’s why I’ve decided to take the eJPTv2 (Junior Penetration Tester) certification.\nThis post is a mix of personal motivation, my preparation strategy, and how I see pentesting tying directly back into the work I’ve done in AWS and incident response.\nWhy Pentesting (and Why Now)? Working in cloud security gives you a strong view of defense: how to build guardrails, monitor events, and enforce least privilege. But defense without understanding the attacker mindset is incomplete.\nPentesting adds that perspective: it shows you how misconfigurations, overlooked IAM roles, or weak monitoring controls can actually be exploited. For me, this was the missing piece to round out my skills.\nAnd with eJPTv2 being an entry-level but hands-on certification, it feels like the right way to start this journey.\nMy Preparation Path I’m preparing for the eJPTv2 in a structured but realistic way. Here’s what’s working for me:\nINE official prep course — following the structured modules ensures I don’t miss the fundamentals. Obsidian for notes — I’m building my own knowledge base, which I’ll be able to reuse later in real projects. Command cheat sheet — keeping a personal reference of go-to tools (Nmap, SQLMap, Hydra, etc.). Hands-on labs in TryHackMe — reinforcing theory with practical hacking experience. This mix gives me both a theoretical foundation and a practical skillset.\nHow This Connects Back to Cloud Security Some might think pentesting is far from cloud, but in reality they’re deeply linked:\nIAM roles \u0026amp; temporary credentials — I wrote about securing them here. From a pentest perspective, weakly scoped roles can be abused to escalate privileges. Incident response in AWS — I covered IR practices in this article. Pentesting helps simulate the incidents you’d need to respond to. Monitoring on a budget — affordable AWS monitoring only works if you know what attackers actually do. Pentesting provides those insights. By blending pentesting with cloud security, I aim to not just build secure environments, but also think like an attacker to validate them.\nWhat’s Next My plan is simple:\nFinish the INE prep course and lab work. Attempt the eJPTv2 exam in the coming weeks. Share my notes, lessons, and reflections here on the blog. This is only the beginning. Long term, I see myself combining cloud security, GRC, and pentesting into a broader career path, where I can secure systems from both compliance and attack perspectives.\nFinal Thoughts This blog started with AWS security. Now, it’s evolving alongside my own career journey. I am still getting to know myself and the vast world of cybersecurity.\nIf you’re a cloud engineer thinking about pentesting (or a pentester curious about cloud), I hope my path resonates with you. The overlap between these two worlds is bigger than most people realize.\nCurious about the tools or techniques I’m using to prepare? Or maybe you’re also studying for the eJPTv2? I’d love to hear from you in the comments or on LinkedIn.\nTogether, let’s keep learning — and keep hacking responsibly.\n","permalink":"https://thehiddenport.dev/posts/ejptv2-journey/","summary":"\u003cp\u003eFor the past years, most of my focus has been on \u003cstrong\u003ecloud security\u003c/strong\u003e — hardening AWS environments, responding to incidents, and making sure access is tightly controlled. But lately, I’ve felt the urge to explore a different side of the equation: \u003cstrong\u003eethical hacking\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eThat’s why I’ve decided to take the \u003cstrong\u003eeJPTv2 (Junior Penetration Tester)\u003c/strong\u003e certification.\u003c/p\u003e\n\u003cp\u003eThis post is a mix of personal motivation, my preparation strategy, and how I see pentesting tying directly back into the work I’ve done in AWS and incident response.\u003c/p\u003e","title":"From Cloud Security to Pentesting: My eJPTv2 Journey"},{"content":"What Is IDOR? Finding and Preventing Insecure Direct Object References in AWS APIs In bug bounty and pentesting, IDOR (Insecure Direct Object Reference) remains one of the most frequent and dangerous vulnerabilities—even today. OWASP defines it as a classic Broken Access Control issue, overwhelming APIs that use predictable or guessable object identifiers (cheatsheetseries.owasp.org). But its real impact goes beyond HTTP—IDOR can silently appear in AWS APIs, Lambda functions, and internal tooling. This post examines how that happens, how bounty hunters find them, and how AWS developers can prevent and detect IDOR effectively.\nPersonal Note I\u0026rsquo;m currently starting my journey into bug bounty hunting. Given my background in AWS security, I realized there’s a natural overlap between the two worlds—especially when it comes to misconfigurations, permission boundaries, and API behavior. This article is my first step into exploring that intersection.\nIf you’re curious to follow along as I dive deeper into bug bounty topics—real findings, tooling, and mindset—stay tuned. More coming soon.\nWhat Is IDOR? IDOR occurs when an application uses user-supplied identifiers (in URL, body, header, or cookie) to reference internal objects without verifying ownership or permissions. It comes in flavors:\nURL tampering: Changing GET /orders?id=1234 to id=1235 to access someone else’s order. Body tampering: Modifying JSON body in POST/PUT to point at unauthorized user ids. Header/cookie manipulation: Modifying session tokens or headers like X-User-ID. Path traversal cases: IDOR via file paths or uploaded object references. Despite best practices, IDOR stays frequent. One bug-hunter reported ~220 IDOR finds out of 650 bounties in a year (reddit.com).\nAWS API IDOR: A Bug Bounty Sweet Spot On AWS, IDOR may “live” in:\nCustom APIs backed by DynamoDB or S3\nExample: GET /user-files?fileId=123 without checking if current user owns fileId Dynamo allows querying without owner checks—easy to exploit Internal tooling using AWS SDK\nUnpublished endpoints with objectKey or roleArn parameters, similar vulnerability Metadata abuse scenarios\nA Lambda calling iam.getUser({UserName: input}) without proper validation Sample IDOR Scenario in AWS POST /internal/api/lambda/invoke { \u0026#34;functionName\u0026#34;: \u0026#34;user-lambdas-arn\u0026#34;, \u0026#34;payload\u0026#34;: { \u0026#34;userId\u0026#34;: \u0026#34;1234\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;listSecrets\u0026#34; } } If backend doesn’t check the authenticated Lambda’s permissions before calling AWS APIs like ListSecrets, an attacker could escalate privileges. Many abused internal lambdas share this pattern.\nWhy IDOR Is Dangerous in AWS Environments In AWS, IDOR can lead to elevated risk beyond stolen data:\nRisk Description Cross-account leakage Exfiltrate data from other AWS accounts AssumeRole abuse Use vulnerable APIs to call sts:AssumeRole({RoleArn:...}) Privilege escalation Access unauthorized secrets, functions, roles Large-scale enumeration Automate API calls to enumerate S3, DB, IAM With AWS’s \u0026ldquo;programmatic everything\u0026rdquo; model, these bugs can scale to severe breaches, as multiple researchers have demonstrated (comolho.com).\nHunting IDOR in AWS APIs 1. Inventory APIs \u0026amp; Parameters Map out all internal APIs—Lambda proxies, API Gateway, custom services—and identify params like userId, resourceId, fileKey, orderId.\n2. Test for direct object access Send requests with someone else’s known identifiers (e.g., ?id=1). Erroneous access or HTTP 200 for wrong objects? Found IDOR.\n3. Automate enumeration With tools like ffuf or burp intruder, fuzz resourceId: 1000–1010, or test for UUID formats. Look for differences in responses.\n4. Monitor enumeration attempts If APIs log every SELECT * WHERE id = ?, watch CloudWatch Logs for weird 404 patterns—indicates enumeration.\n5. Review IAM permissions Check if callers are authorized to access underlying resources (Dynamo, S3). If object access relies solely on client-sent IDs, it’s likely vulnerable.\nPreventing IDOR in AWS Best practices aligned with OWASP guidance include (cheatsheetseries.owasp.org):\nAlways verify object ownership in code:\nconst item = await dynamo.get({Key:{userId: currentUser, objectId: inputId}}); if (!item) throw new Error(\u0026#34;Not found\u0026#34;); Use indirect references for public APIs\nGenerate UUIDs or random keys instead of sequential integers, but access control is non-negotiable. Scope AWS permissions appropriately\nAvoid Resource: \u0026quot;*\u0026quot;. Use fine-grained Condition blocks (e.g., dynamodb:LeadingKeys set to ${aws:userid}). Rate-limit and detect enumeration\nCloudFront or WAF rules can throttle suspicious enumeration patterns. Log everything\nEmit structured logs to CloudWatch, alert on spikes of unauthorized requests or repeated access attempts. Detection \u0026amp; Alerting Strategy Use CloudTrail + EventBridge for IDOR Detection Any API returning 404 or 200 on unexpected IDs can trigger alerts:\n{ \u0026#34;detail-type\u0026#34;: [\u0026#34;API Call via CloudTrail\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;eventSource\u0026#34;: [\u0026#34;execute-api.amazonaws.com\u0026#34;], \u0026#34;httpStatus\u0026#34;: [\u0026#34;200\u0026#34;], \u0026#34;requestParameters\u0026#34;: { \u0026#34;resourceId\u0026#34;: [\u0026#34;*\u0026#34;] } } } Then trigger SNS or Lambda to log suspicious enumeration.\nLog-based alerts in CloudWatch Watch for:\nMany 404s within a minute Access to resources owned by a different AWS account or user Putting It All Together: A Hardened Example API Gateway → Lambda → DynamoDB access Lambda code strictly checks userId ownership IAM policy only allows access to items under ${aws:userid} WAF blocks \u0026gt;50 requests/minute per IP to /internal/api/ CloudTrail/CloudWatch logs feed into SIEM alerts for anomalies Why IDOR Still Wins in Bug Bounty Despite being well-known, IDOR persists due to:\nFast development cycles: devs quickly expose objects without validation. False confidence in UUIDs: obfuscation ≠ security. Lack of server-side enforcement: clients control identifiers, so attackers can enumerate. Related Reading My full IAM least privilege guide EventBridge detection for privilege escalation EC2 Hardening \u0026amp; AMI automation Final Thoughts IDOR is simple to understand—but complex to eliminate completely, especially in cloud environments. With thoughtful access control, logging, detection, and auditing, you can significantly reduce risk. For bug hunters, IDOR remains a low-hanging but impactful vulnerability, especially when combined with AWS APIs or internal tools.\nKeep hunting, keep securing—and if you find an AWS-based IDOR, do share the example (anonymized) so the whole community learns with you.\n","permalink":"https://thehiddenport.dev/posts/aws-preventing-idor/","summary":"Learn what IDOR is, why it\u0026rsquo;s so common (and dangerous), see real AWS-related examples, and discover prevention and detection methods for robust API security.","title":"What Is IDOR? Finding and Preventing Insecure Direct Object References in AWS APIs"},{"content":"Getting Started with Amazon GuardDuty: Setup, Findings, and SIEM Integration Amazon GuardDuty is a threat detection service that continuously monitors your AWS accounts and workloads for malicious activity and delivers detailed security findings for visibility and remediation. In this guide, we\u0026rsquo;ll walk through setting up GuardDuty, understanding its findings, and integrating it with SIEM solutions to enhance your security posture.\nEnabling GuardDuty To start using GuardDuty:\nAccess the GuardDuty Console: Navigate to the Amazon GuardDuty console. Enable GuardDuty: Click on \u0026ldquo;Get started\u0026rdquo; and then \u0026ldquo;Enable GuardDuty\u0026rdquo; for your desired region. GuardDuty is a regional service, so you\u0026rsquo;ll need to enable it in each region you want to monitor. Multi-Account Setup: If you\u0026rsquo;re using AWS Organizations, you can designate a GuardDuty administrator account to manage GuardDuty across multiple accounts. This setup allows centralized management of findings and configurations. Understanding GuardDuty Findings Once enabled, GuardDuty analyzes various data sources, including VPC Flow Logs, AWS CloudTrail event logs, and DNS logs, to identify unexpected and potentially unauthorized or malicious activity within your AWS environment.\nTypes of Findings GuardDuty findings are categorized into several types, such as:\nReconnaissance: Activities like port scanning or probing. Unauthorized Access: Attempts to access AWS resources without proper permissions. Malware: Detection of known malware signatures or behaviors. Data Exfiltration: Unusual data transfers that may indicate data theft. Each finding includes details like the affected resource, the nature of the threat, and its severity level (Low, Medium, High).\nViewing Findings You can view and manage your GuardDuty findings:\nConsole: Navigate to the \u0026ldquo;Findings\u0026rdquo; section in the GuardDuty console. AWS CLI: Use commands like aws guardduty list-findings and aws guardduty get-findings. API: Integrate with your applications using the GuardDuty API. Generating Sample Findings To familiarize yourself with GuardDuty findings and test your alerting mechanisms, you can generate sample findings:\nConsole: In the GuardDuty console, go to \u0026ldquo;Settings\u0026rdquo; and select \u0026ldquo;Generate sample findings.\u0026rdquo; AWS CLI: Use the command: aws guardduty create-sample-findings --detector-id \u0026lt;detector-id\u0026gt; These sample findings simulate various threat scenarios and are clearly marked as samples.\nIntegrating GuardDuty with SIEM Solutions Integrating GuardDuty with a Security Information and Event Management (SIEM) system allows for centralized monitoring and analysis of security events.\nIntegration via Amazon EventBridge and Kinesis Data Firehose Create a Kinesis Data Firehose Delivery Stream: Set up a delivery stream to your SIEM destination, such as Amazon S3, Amazon OpenSearch Service, or a third-party endpoint. Set Up EventBridge Rule: Configure an EventBridge rule to capture GuardDuty findings and route them to the Kinesis Data Firehose delivery stream. Configure SIEM to Ingest Data: Ensure your SIEM solution is set up to ingest data from the specified destination. Integration via AWS Security Hub Enable AWS Security Hub: Turn on Security Hub in your AWS account. Integrate GuardDuty with Security Hub: GuardDuty findings will automatically be sent to Security Hub. Set Up Custom Actions: Create custom actions in Security Hub to send findings to EventBridge, which can then route them to your SIEM. Best Practices Enable GuardDuty in All Regions: Threats can originate from any region; enabling GuardDuty across all regions ensures comprehensive coverage. Regularly Review Findings: Set up automated alerts for high-severity findings and review them promptly. Integrate with Other AWS Services: Use AWS Lambda for automated remediation and AWS Config for compliance checks. Export Findings for Long-Term Analysis: Store findings in Amazon S3 for historical analysis and compliance purposes. Conclusion Amazon GuardDuty provides a robust solution for continuous threat detection in your AWS environment. By understanding its findings and integrating them with SIEM solutions, you can enhance your security monitoring and response capabilities. Regularly reviewing and acting upon GuardDuty findings is essential for maintaining a strong security posture in the cloud.\n","permalink":"https://thehiddenport.dev/posts/aws-guardduty-setup/","summary":"A comprehensive guide to setting up Amazon GuardDuty, interpreting its findings, and integrating with SIEM systems to bolster AWS security.","title":"Getting Started with Amazon GuardDuty: Setup, Findings, and SIEM Integration"},{"content":"Detecting Privilege Escalation in AWS Using CloudTrail and EventBridge One of the most dangerous threats in an AWS environment is privilege escalation—when an entity (a user, role, or service) gains more permissions than it should, either by misconfiguration or abuse. Detecting these escalation attempts is essential to protecting your cloud environment.\nAWS does not provide out-of-the-box detection for many of these patterns, but with CloudTrail, EventBridge, and some detection engineering, you can build native alerts for high-risk API calls that indicate an escalation in progress—or one about to happen.\nThis article will dive deep into:\nWhy privilege escalation is critical How attackers typically escalate privileges in AWS Which CloudTrail events to monitor How to configure EventBridge to catch suspicious patterns How to alert in real-time (SNS, Lambda, etc.) Caveats and tuning recommendations Why Privilege Escalation Matters in AWS Unlike traditional infrastructure, in AWS permissions are programmable, and every misstep can have systemic impact. Privilege escalation is not theoretical—it has been exploited both in internal red team exercises and real-world attacks.\nFor example, an attacker with limited access to Lambda functions might:\nModify an existing function to assume a high-privilege IAM role Add a new inline policy to their own user Or pass an admin role to an EC2 instance they control All of these leave traces in CloudTrail—if you\u0026rsquo;re watching.\nCommon Privilege Escalation Techniques in AWS Most escalation paths involve IAM or STS actions. Here are common patterns:\nAction What It Does iam:AttachUserPolicy / AttachRolePolicy Grants an existing policy to a principal iam:PutUserPolicy / PutRolePolicy Creates an inline policy (can contain anything) iam:PassRole + ec2:RunInstances Launches EC2 with powerful role attached lambda:UpdateFunctionCode + iam:PassRole Runs arbitrary code under elevated permissions sts:AssumeRole Switches identity if allowed by trust policy iam:CreatePolicyVersion May set an older, more permissive version as active Even if you\u0026rsquo;re using SCPs or guardrails, these events are useful for threat hunting or detection.\nCloudTrail Configuration Ensure you have:\nCloudTrail enabled in all regions Logging for management events Optionally delivering to an S3 bucket and integrated with CloudWatch Logs to bypass the 90 day retention limit of Cloudtrail All of the mentioned escalation actions are management events, and appear in CloudTrail as part of the eventName field.\nExample CloudTrail log (truncated):\n{ \u0026#34;eventName\u0026#34;: \u0026#34;AttachUserPolicy\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;iam.amazonaws.com\u0026#34;, \u0026#34;userIdentity\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;IAMUser\u0026#34;, \u0026#34;userName\u0026#34;: \u0026#34;alice\u0026#34; }, \u0026#34;requestParameters\u0026#34;: { \u0026#34;userName\u0026#34;: \u0026#34;alice\u0026#34;, \u0026#34;policyArn\u0026#34;: \u0026#34;arn:aws:iam::aws:policy/AdministratorAccess\u0026#34; }, ... } Creating Detection Rules with EventBridge EventBridge can subscribe to the CloudTrail event stream and match on suspicious API calls. You can then trigger notifications or automated actions.\nRule Example: Detect AttachUserPolicy { \u0026#34;source\u0026#34;: [\u0026#34;aws.iam\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;AWS API Call via CloudTrail\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;eventName\u0026#34;: [\u0026#34;AttachUserPolicy\u0026#34;, \u0026#34;PutUserPolicy\u0026#34;], \u0026#34;requestParameters.policyArn\u0026#34;: [{ \u0026#34;prefix\u0026#34;: \u0026#34;arn:aws:iam::aws:policy/AdministratorAccess\u0026#34; }] } } This rule matches when someone attaches AdministratorAccess to themselves (or anyone).\nOther Useful Event Names to Watch CreatePolicy CreatePolicyVersion SetDefaultPolicyVersion PutRolePolicy PassRole AssumeRole If you’re watching cross-service escalation:\nRunInstances (check if iam:PassRole was used) UpdateFunctionCode (especially if the Lambda uses an elevated role) Alerting via SNS or Lambda Once your EventBridge rule matches, you can:\nTrigger an SNS notification (email, Slack, SMS) Invoke a Lambda function that writes to a SIEM, sends to Discord, or logs to S3 Write to CloudWatch Logs for later review Example: Send to SNS { \u0026#34;State\u0026#34;: \u0026#34;ENABLED\u0026#34;, \u0026#34;Targets\u0026#34;: [ { \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:sns:us-east-1:111122223333:PrivEscAlerts\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;PrivEscAlertTarget\u0026#34; } ] } Tuning and Limitations False Positives Some actions might be part of normal automation pipelines Devs might update Lambda or IAM configs legitimately You can reduce noise by:\nFiltering on userIdentity.principalId or userName Excluding known automation roles (with conditions in EventBridge) Only alerting on attachments of privileged policies (e.g., AdministratorAccess, PowerUserAccess) Blind Spots Inline policy abuse might not be obvious If CloudTrail isn’t enabled in all regions, you’ll miss stuff Identity switching (sts:AssumeRole) requires combining multiple events to trace the full chain Related Reading If this post interests you, check these out:\nEnforcing Least Privilege in AWS IAM AWS Incident Response Toolkit Securing EC2 Access with AWS Systems Manager AWS Security Checklist 2025 Conclusion Privilege escalation is one of the most critical actions you need to monitor in AWS. While AWS provides the logs (via CloudTrail), it’s your responsibility to wire up detection logic. Thankfully, with EventBridge and a few well-designed rules, you can begin detecting these escalation attempts in near real-time.\nEven a single detection rule—targeting AttachUserPolicy with AdministratorAccess—can surface abuse before it becomes a breach.\nDon’t wait for an incident to act. Harden your detection stack today.\n","permalink":"https://thehiddenport.dev/posts/aws-detecting-privilege-escalation/","summary":"A deep technical guide to setting up AWS-native detection for privilege escalation using CloudTrail, EventBridge, and minimal infrastructure.","title":"Detecting Privilege Escalation in AWS Using CloudTrail and EventBridge"},{"content":"Building a Hardened Amazon Linux 2 AMI for Secure EC2 Deployments In cloud environments, spinning up secure, hardened EC2 instances rapidly and consistently is a critical security and operational requirement. Manually configuring instances after launch is error-prone and inefficient. The solution? Automate the creation of hardened, compliant AMIs using AWS EC2 Image Builder.\nThis article walks you through building a hardened Amazon Linux 2 AMI using EC2 Image Builder, integrating CIS benchmark checks, IMDSv2 enforcement, auditd, CloudWatch logging, and common security best practices.\nWhy Build a Hardened AMI? While Amazon Linux 2 is secure by default, production workloads demand additional layers of security:\nConsistent baseline configuration across instances Disabling unnecessary services and users Enforcing instance metadata protection (IMDSv2 only) Pre-installed monitoring and audit agents Automatic patching and versioning of AMIs Building a custom hardened AMI ensures every EC2 instance launched from it meets your organization’s security standards from day one.\nStep 1: Overview of EC2 Image Builder EC2 Image Builder is an AWS-managed service that automates creating, testing, and distributing AMIs. It uses pipeline workflows where you define:\nBase image (Amazon Linux 2 official image) Components (scripts and configuration steps) Tests (CIS benchmark validation) Distribution settings (account and region targets) Step 2: Define Your Base Image and Components Start with the official Amazon Linux 2 AMI as the base. Add components such as:\nPatch updates: Apply all current OS patches automatically. CIS Benchmark hardening: Disable unnecessary services, set secure kernel parameters, lock down SSH configuration. IMDSv2 enforcement: Disable IMDSv1 by configuring the aws-ec2-metadata-service to require tokens. Auditd setup: Enable system auditing and forward logs to CloudWatch Logs. Install monitoring agents: CloudWatch agent, osquery for endpoint visibility. You can create custom components in EC2 Image Builder or use community-supported ones, ensuring scripts are idempotent and secure.\nStep 3: Create the Image Pipeline Configure the image pipeline with these key settings:\nSchedule: Weekly or monthly builds to include the latest patches. Tests: Run automated CIS Benchmark compliance tests after build. Distribution: Share the hardened AMI across your AWS accounts or regions. Tags and Naming: Use semantic versioning and tags for easy identification. Example AWS CLI snippet to create a simple pipeline:\naws imagebuilder create-image-pipeline --cli-input-json file://pipeline-config.json Step 4: Validate Your Hardened AMI After each build, run tests to verify:\nCIS benchmark pass rate (using open-source tools or AWS Inspector) IMDSv1 is disabled, only IMDSv2 accessible Audit logs forwarding to CloudWatch SSH key restrictions and root login disabled Automate these checks to fail pipelines if hardening criteria aren’t met.\nStep 5: Launch and Use Your Hardened AMI Use your hardened AMI for:\nProduction EC2 instances Auto Scaling groups ECS container instances (if applicable) Maintain version control on AMIs and rotate them regularly for patch compliance.\nBest Practices and Tips Combine EC2 Image Builder with AWS Systems Manager Automation to patch running instances. Store your pipeline definitions in version control (e.g., Git) for auditability. Use IMDSv2 exclusively to mitigate SSRF risks. Monitor your hardened AMIs with CloudWatch and AWS Config rules. Document your build process and security rationale. Related Reading Hardening EC2 Instances for AWS Security Securing EC2 Access with AWS Systems Manager (No SSH) AWS Incident Response Toolkit Enforcing Least Privilege in AWS IAM Final Thoughts Building and maintaining hardened AMIs is a cornerstone of secure AWS infrastructure. Automating this process with EC2 Image Builder not only improves security posture but also accelerates deployment workflows. Start small, automate everything, and iterate for continuous improvement.\n","permalink":"https://thehiddenport.dev/posts/aws-ami-hardening/","summary":"Step-by-step guide to build a hardened Amazon Linux 2 AMI with EC2 Image Builder including CIS benchmarks, IMDSv2 enforcement, auditd, and logging configuration.","title":"Building a Hardened Amazon Linux 2 AMI for Secure EC2 Deployments"},{"content":"Enforcing Least Privilege in AWS IAM with Access Analyzer and Last Access Data The principle of least privilege is foundational in securing AWS environments, yet in practice, most IAM roles are over-permissioned by default. This article walks through how to actually enforce least privilege in AWS using tools like IAM Access Analyzer, service access reports, CloudTrail, and real-time alerting.\nWhy Least Privilege Is So Hard in AWS IAM in AWS is extremely flexible — and that\u0026rsquo;s exactly the problem. Roles are often created in a rush, permissions are copied from other roles, and nobody circles back to audit them. Over time, permissions accumulate and expose your environment to unnecessary risk.\nCommon issues include:\nRoles with wildcards like s3:*, iam:*, or ec2:* Stale roles that no longer serve a purpose Unused permissions that could be safely revoked Lack of insight into what permissions are actually being used You can’t fix what you can’t see — so let’s start by turning on the lights.\nStep 1: Use Access Analyzer to Audit External Access IAM Access Analyzer helps you detect resource-based policies that grant access to external entities — like sharing an S3 bucket publicly or exposing a KMS key to a different account.\naws accessanalyzer create-analyzer \\ --type ACCOUNT \\ --name security-audit Once active, it scans all supported resources and generates findings like:\n\u0026ldquo;S3 bucket is shared with the public\u0026rdquo; \u0026ldquo;KMS key accessible to another AWS account\u0026rdquo; This is your first pass: shut down explicit external access that violates least privilege.\nRead more in my Access Analyzer deep dive\nStep 2: Generate Service Last Accessed Data To determine which permissions are not used, AWS lets you query when a principal last accessed a service:\naws iam generate-service-last-accessed-details \\ --arn arn:aws:iam::123456789012:role/MyAppRole Then fetch the report:\naws iam get-service-last-accessed-details \\ --job-id \u0026lt;job-id\u0026gt; This reveals:\nServices that haven\u0026rsquo;t been accessed in 90+ days Evidence to trim down Action lists in your policies This is your best friend for permission pruning.\nStep 3: Refine Policies with CloudTrail + Policy Simulator For fine-tuning:\nUse CloudTrail to view actual API calls made by a role. Feed those into the IAM Policy Simulator to determine what the minimum required permissions are. Manually edit the policy or use tools like repokid for automation. This is tedious but worth it — it’s the real way to enforce least privilege.\nStep 4: Detect Escalation in Real-Time Least privilege isn\u0026rsquo;t just about static policies — it\u0026rsquo;s about monitoring changes too.\nUse EventBridge + CloudTrail to catch events like:\nCreatePolicy or AttachRolePolicy with wildcards Roles being granted AdministratorAccess Roles using new services suddenly Send these to SNS, Slack, or log them into a central detection toolkit.\nBonus: Automate Least Privilege Reviews with Lambda Want to get proactive?\nSchedule a Lambda that runs generate-service-last-accessed-details weekly Parse results and send a report to security engineers or your team chat Automatically open a ticket if iam:PassRole appears on a dev role You can add this to your IR automation playbook.\nRelated Reading Common AWS IAM Misconfigurations IAM Access Analyzer Deep Dive AWS IR Toolkit with Detection Rules Securing Temporary AWS Credentials Happy hunting\n","permalink":"https://thehiddenport.dev/posts/aws-enforcing-least-privilege/","summary":"This article shows how to audit and refine IAM permissions using Access Analyzer, CloudTrail, and service access history — enforcing least privilege the right way in AWS.","title":"Enforcing Least Privilege in AWS IAM with Access Analyzer and Last Access Data"},{"content":"Introduction Traditional SSH access to EC2 instances poses several security challenges, including the management of SSH keys, exposure of ports, and lack of centralized auditing. AWS Systems Manager Session Manager offers a secure and auditable alternative, allowing you to manage EC2 instances without opening inbound ports or maintaining bastion hosts.\nThis guide provides a step-by-step approach to configuring Session Manager for secure EC2 access, aligning with AWS\u0026rsquo;s official documentation and best practices.\nPrerequisites Before proceeding, ensure the following:\nSSM Agent Installed: Amazon EC2 instances must have the SSM Agent installed. Amazon Linux 2 and Ubuntu 16.04 or later come with the agent pre-installed. For other operating systems, refer to the SSM Agent installation guide.\nIAM Role with SSM Permissions: Instances require an IAM role with the AmazonSSMManagedInstanceCore policy attached. This policy grants the necessary permissions for Systems Manager to manage the instance.\nOutbound Internet Access or VPC Endpoints: Instances must be able to communicate with Systems Manager endpoints. This can be achieved via outbound internet access (e.g., through a NAT gateway) or by configuring VPC endpoints for Systems Manager.\nStep 1: Create an IAM Role for SSM Navigate to the IAM Console.\nSelect Roles \u0026gt; Create role.\nChoose AWS service as the trusted entity and select EC2.\nClick Next: Permissions.\nAttach the AmazonSSMManagedInstanceCore policy.\nProceed through the remaining steps to name and create the role.\nStep 2: Attach the IAM Role to EC2 Instances Open the EC2 Console.\nSelect the instance(s) you wish to manage.\nChoose Actions \u0026gt; Security \u0026gt; Modify IAM Role.\nSelect the IAM role created in Step 1 and apply the changes.\nStep 3: Verify SSM Agent Status Ensure the SSM Agent is running on your instance:\nsudo systemctl status amazon-ssm-agent If the agent is not running, start it with:\nsudo systemctl start amazon-ssm-agent Step 4: Connect to the Instance Using Session Manager With the IAM role attached and the SSM Agent running, you can initiate a session:\nUsing AWS Console Navigate to the Systems Manager Console.\nSelect Session Manager \u0026gt; Start session.\nChoose the instance and click Start session.\nUsing AWS CLI Ensure you have the Session Manager plugin installed.\nInitiate a session with:\naws ssm start-session --target i-0123456789abcdef0 Replace i-0123456789abcdef0 with your instance ID.\nStep 5: Enhance Security by Disabling SSH Access After verifying that Session Manager access works as intended, you can enhance security by disabling SSH access:\nSecurity Groups: Remove inbound rules for port 22.\nKey Pairs: Avoid assigning key pairs to instances.\nBastion Hosts: Decommission any bastion hosts used for SSH access.\nThis approach reduces the attack surface and aligns with the principle of least privilege.\nStep 6: Configure Logging for Auditing To maintain an audit trail of session activity:\nIn the Systems Manager Console, navigate to Session Manager \u0026gt; Preferences.\nClick Edit and enable logging.\nChoose to send session logs to Amazon S3 and/or Amazon CloudWatch Logs.\nThis configuration ensures that all session activity is recorded for compliance and auditing purposes.\nAbsolutely! Let\u0026rsquo;s enhance your article by adding two comprehensive sections: Common Issues and Troubleshooting and Monitoring SSM Agent with CloudWatch. These additions will provide readers with practical insights into potential pitfalls and proactive monitoring strategies.\nCommon Issues and Troubleshooting While AWS Systems Manager Session Manager offers a secure and efficient method for managing EC2 instances, users may encounter certain challenges during setup or operation. Below are some common issues and their resolutions:\n1. Instance Not Appearing in Session Manager Issue: The EC2 instance does not appear in the Session Manager console.\nPossible Causes and Solutions:\nSSM Agent Not Installed or Running: Ensure that the SSM Agent is installed and actively running on the instance. For Amazon Linux 2 and Ubuntu 16.04 or later, the agent is pre-installed. For other operating systems, refer to the SSM Agent installation guide.\nMissing IAM Role or Incorrect Permissions: Verify that the instance has an IAM role attached with the AmazonSSMManagedInstanceCore policy. This policy grants the necessary permissions for Systems Manager to manage the instance.\nNetwork Connectivity Issues: The instance must be able to communicate with Systems Manager endpoints. Ensure that the instance has outbound internet access or is configured with the appropriate VPC endpoints for Systems Manager.\n2. Session Initiation Fails Issue: Attempting to start a session results in an error.\nPossible Causes and Solutions:\nSSM Agent Version Incompatibility: Ensure that the SSM Agent is updated to the latest version. Older versions may lack support for certain features or have known issues.\nSession Manager Plugin Missing: When using the AWS CLI, the Session Manager plugin must be installed. Follow the installation instructions to set it up.\nIAM User Permissions: The IAM user initiating the session must have the necessary permissions, such as ssm:StartSession. Review and update IAM policies as needed.\n3. SSM Agent Connectivity Issues Issue: The SSM Agent cannot connect to Systems Manager endpoints.\nPossible Causes and Solutions:\nFirewall or Security Group Restrictions: Ensure that the instance\u0026rsquo;s security groups and network ACLs allow outbound HTTPS (port 443) traffic to Systems Manager endpoints.\nDNS Resolution Problems: Verify that the instance can resolve domain names. Misconfigured DNS settings can prevent the agent from reaching AWS services.\nEndpoint Configuration: If using VPC endpoints, confirm that they are correctly configured and associated with the appropriate route tables and security groups.\nFor a comprehensive troubleshooting guide, refer to the AWS Systems Manager Troubleshooting Documentation.\nMonitoring SSM Agent with CloudWatch Proactive monitoring of the SSM Agent ensures that you are promptly alerted to any issues, maintaining the reliability and security of your EC2 instances. Here\u0026rsquo;s how to set up monitoring using Amazon CloudWatch:\n1. Send SSM Agent Logs to CloudWatch Logs Steps:\nCreate a CloudWatch Log Group: In the CloudWatch console, create a log group to store SSM Agent logs.\nConfigure the SSM Agent to Send Logs: Modify the SSM Agent configuration to send logs to the newly created log group. This can be done by editing the agent\u0026rsquo;s configuration file or using Systems Manager Run Command.\nRestart the SSM Agent: After configuration, restart the SSM Agent to apply changes.\nFor detailed instructions, consult the AWS Systems Manager Monitoring Guide.\n2. Create Metric Filters and Alarms Steps:\nDefine Metric Filters: In the CloudWatch console, create metric filters to identify specific log events, such as agent start or stop events. For example, to detect when the agent stops:\nf i l t e r p a t t e r n : \" S t o p p i n g s s m a g e n t w o r k e r \" Create Alarms: Based on the metric filters, set up alarms to notify you when certain thresholds are met. For instance, if the agent stops unexpectedly, an alarm can trigger an SNS notification.\nSubscribe to Notifications: Ensure that relevant personnel are subscribed to the SNS topic to receive timely alerts.\nFor a practical example and additional guidance, refer to the AWS blog post on Monitoring the Health of AWS Systems Manager Agent Using Amazon CloudWatch.\nAdditional Considerations User Permissions: Control who can start sessions by defining IAM policies that grant ssm:StartSession permissions to specific users or roles.\nPort Forwarding: Session Manager supports port forwarding, allowing secure access to applications running on instances without opening additional ports.\nHybrid Environments: Session Manager can manage on-premises servers and virtual machines by registering them as managed instances.\nConclusion By leveraging AWS Systems Manager Session Manager, you can eliminate the need for SSH access to EC2 instances, thereby enhancing security, simplifying access management, and ensuring comprehensive auditing. This approach aligns with AWS\u0026rsquo;s best practices for secure and compliant infrastructure management.\nFor further reading on IAM misconfigurations and security risks, refer to my previous article: AWS IAM Misconfigurations: Security Risks and How to Fix Them.\nTo explore incident response strategies in AWS, check out: Incident Response in AWS: A Practical Playbook.\nFor tools to automate incident response, visit: AWS Incident Response Toolkit.\nLearn about securing temporary AWS credentials here: Securing Temporary AWS Credentials with STS.\n","permalink":"https://thehiddenport.dev/posts/aws-securing-ec2-access-with-ssm/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eTraditional SSH access to EC2 instances poses several security challenges, including the management of SSH keys, exposure of ports, and lack of centralized auditing. AWS Systems Manager Session Manager offers a secure and auditable alternative, allowing you to manage EC2 instances without opening inbound ports or maintaining bastion hosts.\u003c/p\u003e\n\u003cp\u003eThis guide provides a step-by-step approach to configuring Session Manager for secure EC2 access, aligning with AWS\u0026rsquo;s official documentation and best practices.\u003c/p\u003e","title":"Securing EC2 Access with AWS Systems Manager Session Manager: Eliminating SSH"},{"content":"Perfect — let’s start by drafting the updated EC2 Hardening Guide. I’ll keep it detailed, actionable, and structured so it’s easy to follow, while also signaling authority to both readers and Google.\nEC2 Hardening Guide (Updated 2025) Last updated: September 2025. This guide consolidates AWS official best practices, CIS Benchmarks, and real-world experience to help you secure Amazon EC2 instances.\n1. System Updates \u0026amp; Patch Management Enable automatic patching with AWS Systems Manager (SSM):\nsudo yum update -y # Amazon Linux sudo apt-get update \u0026amp;\u0026amp; sudo apt-get upgrade -y # Ubuntu/Debian Use SSM Patch Manager to automate OS/security updates across fleets:\nCreate a Patch Baseline. Attach to EC2 via IAM Role with SSM managed policy. Schedule via Maintenance Windows. 2. Least Privilege IAM Roles Never hardcode credentials inside EC2.\nAttach an Instance Role with only the permissions needed:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:GetObject\u0026#34;], \u0026#34;Resource\u0026#34;: [\u0026#34;arn:aws:s3:::mybucket/*\u0026#34;] } ] } Enable IAM Access Analyzer to detect overly broad permissions.\n3. Network Security Restrict inbound traffic with Security Groups:\nDeny 0.0.0.0/0 on SSH/RDP; instead allow only trusted IP ranges. Example rule: 22/tcp → 203.0.113.0/24. Add Network ACLs for an extra layer of defense.\nRequire VPN/Bastion host for administrative access.\n4. OS Hardening Disable root login over SSH:\nsudo nano /etc/ssh/sshd_config PermitRootLogin no PasswordAuthentication no Enforce key-based authentication (it is preferable to only allow SSM auth)\nConfigure firewalld/ufw inside the OS for host-based filtering.\nRemove unused software packages.\n5. Disk \u0026amp; Data Protection Encrypt EBS volumes with AWS KMS CMK. Use automatic snapshot encryption for backups. Enable EBS fast snapshot restore only in secure regions. If handling sensitive data → enforce KMS key rotation (every 365 days). 6. Monitoring \u0026amp; Logging Enable CloudTrail for all regions → send logs to S3 + CloudWatch Logs.\nUse GuardDuty for continuous threat detection.\nEnable VPC Flow Logs for visibility into network traffic.\nInstall CloudWatch Agent on EC2:\nsudo yum install amazon-cloudwatch-agent -y /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-config-wizard 7. Backup \u0026amp; Recovery Use AWS Backup with lifecycle rules for snapshots. Store snapshots in separate accounts (backup vaults). Regularly test recovery from snapshots/AMI. 8. Compliance \u0026amp; Benchmarking Use AWS Security Hub with CIS EC2 controls enabled.\nRun AWS Config with rules like:\nrestricted-ssh ec2-instance-managed-by-ssm ec2-ebs-encryption-by-default I\u0026rsquo;ll be posting soon a full walthrough about Meeting CIS Benchmarks for EC2.\nWith these steps, your EC2 instances are aligned with AWS and CIS best practices, reducing attack surface while staying auditable for compliance.\n","permalink":"https://thehiddenport.dev/posts/aws-ec2-hardening/","summary":"This guide delves into the technical aspects of hardening EC2 instances, covering topics from instance selection to monitoring and automation, aligning with AWS\u0026rsquo;s security recommendations.","title":"Hardening EC2 Instances for AWS Security: A Practical Guide"},{"content":" Why I Built This Toolkit After sharing my Incident Response in AWS article and a free downloadable checklist, I received a lot of feedback — mostly from engineers saying the same thing:\n“This is helpful, but I still have to piece everything together.”\nSo I built a complete AWS Incident Response Toolkit.\nThis bundle goes much further than the checklist: ready-to-use Terraform to deploy the notification pipeline, Python scripts for SES and Slack alerts, and a matrix of tools you can use during forensic investigations. It’s designed to save you time, avoid mistakes, and make response feel a lot less chaotic.\nWhat’s Inside the Toolkit Here’s a look at what’s included:\nFile Type Description Incident response playbook template.pdf PDF Editable playbook aligned with ISO 27001 and AWS workflows Notification_Flows_Extended.md Markdown 3 notification flow examples (SES, Slack, SQS) Cloud_Forensics_Tool_Matrix.xlsx Excel A categorized list of native and open-source tools for memory, logs, and more terraform/ Code Terraform code to deploy EventBridge + Lambda pipeline (deployment-ready) python/email_notification.py Code Lambda-compatible Python script to send SES alerts on new findings python/slack_notification.py Code Example Slack webhook integration (extendable) README.md Markdown Full usage instructions 💡 You don’t have to be a Terraform expert — just update a few variables and deploy with terraform apply.\nUse Cases Whether you\u0026rsquo;re:\nA cloud security engineer handling incidents solo A DevSecOps team responding to GuardDuty findings A consultant setting up IR workflows for clients …this toolkit helps you deploy faster, communicate better, and keep a paper trail.\nWhere to Get It 🛠️ You can grab the full toolkit here: 👉 Buy the AWS IR Toolkit on Gumroad\nI’ve priced it at €9 to make it accessible, but still sustainable for me to keep updating it.\nYou’ll get all future updates for free — including any new scripts, improved playbook versions, or Notion templates I release.\nThere is also a Gumroad community set up where you can suggest additions to the bundle.\nFinal Thoughts This was built from real-world pain. I just wanted to make something useful that I wish existed when I was building IR workflows.\nIf you grab the toolkit and find it useful, I’d love to hear from you. Your feedback will help shape version 2.\nUntil then — stay ready.\n– Javier\n","permalink":"https://thehiddenport.dev/posts/aws-ir-toolkit/","summary":"After publishing my free AWS IR checklist, I decided to go one step further — a full incident response toolkit with Terraform code, automation scripts, and ready-to-use templates. Here’s what’s inside.","title":"AWS Incident Response Toolkit: Resources \u0026 Templates"},{"content":" Monitoring in AWS doesn’t have to be expensive. In this guide, we’ll walk through real-world strategies to detect and respond to security events in AWS without blowing your budget — using a mix of native tooling, automation, and open-source solutions.\nTable of Contents Introduction Why AWS Monitoring Costs Spiral Key Principles for Cost-Effective Monitoring Low-Cost Native AWS Tools for Security Monitoring Open-Source Solutions That Complement AWS Example Architectures \u0026amp; Pricing Automation Snippets for Cost-Efficient Alerts Common Pitfalls to Avoid Conclusion Introduction When people talk about security monitoring in AWS, the conversation quickly jumps to expensive SIEM tools or overengineered pipelines. But if you\u0026rsquo;re running lean, or just want better control over where your money is going, you can achieve excellent security visibility with surprisingly low cost.\nThis article breaks down how to do exactly that.\nWe’ll cover:\nWhich AWS services give you security telemetry for free (or close to it) How to set up event-driven alerts with minimal runtime costs Open-source options that plug into AWS without turning into money pits Architecture patterns for teams of all sizes By the end, you\u0026rsquo;ll have a solid strategy that keeps your AWS environments monitored — without needing to sell an organ.\nWhy AWS Monitoring Costs Spiral Understanding the primary cost drivers helps you design smarter from the start:\nCloudWatch Logs: billed by ingestion volume and retention duration. CloudTrail: multi-region trails with long-term S3 storage + optional CloudTrail Lake. AWS Config: charges per rule evaluation. Athena queries: priced per TB scanned — expensive if used without partitions. SIEM integrations: agents like Datadog or Rapid7 can multiply costs fast. Add to that naive setups like \u0026ldquo;log everything forever\u0026rdquo; or \u0026ldquo;query daily with no filters,\u0026rdquo; and you\u0026rsquo;re in trouble.\nKey Principles for Cost-Effective Monitoring Start with native tools: AWS services like EventBridge, CloudTrail, and Config already provide tons of signal. Event-driven \u0026gt; polling: Trigger Lambdas from EventBridge or GuardDuty rather than running scheduled functions. Don\u0026rsquo;t store what you won’t analyze: Be selective about what you keep beyond 30–90 days. Use cold storage smartly: S3 + Glacier Deep Archive = cheap long-term retention. Treat logs as tiered assets: hot (analyzed), warm (queryable), cold (archived). Low-Cost Native AWS Tools for Security Monitoring 🔍 CloudTrail Captures API-level activity. Free for 90 days in Event History. For long-term: use an org-wide trail → S3 + lifecycle policy. What to watch for:\nConsoleLogin AssumeRole UnauthorizedOperation Use EventBridge rules or metric filters on these events to alert.\n📈 CloudWatch Logs \u0026amp; Metric Filters Logs cost per GB ingested and retained. Set up metric filters on important events (from CloudTrail logs) to track threats. Example filters:\nRoot login usage Access denied errors Security group changes Pair with CloudWatch Alarms to notify via SNS.\n🎯 EventBridge Serverless event router. Filter and forward events to Lambda, SNS, or other targets. Use for:\nSecurity Hub findings IAM changes GuardDuty alerts Pricing is negligible at moderate volume.\n⚙️ AWS Config (targeted) Only enable the rules you care about, like:\nS3 bucket public access IAM root usage CloudTrail enabled Stay under the free tier (100 evaluations/month) or use it sparingly.\n🚨 Security Hub + GuardDuty Free for 30 days, then priced by finding volume. Use with EventBridge to auto-respond only to High/Medium severity. Open-Source Solutions That Complement AWS 🛡️ Wazuh Lightweight SIEM alternative Deploy in ECS Fargate Spot or EC2 t3a.small Collect CloudTrail logs via Filebeat Store in S3 with lifecycle policies Bonus: enrich with GeoIP, threat feeds, file integrity monitoring\n🔍 OpenSearch (self-hosted) Use a minimal cluster (e.g., 2 nodes in t3.medium) or serverless preview Avoid expensive retention — snapshot to S3 after 7–14 days Kibana dashboards for audit logs, login attempts, or GuardDuty 📊 Prometheus + Grafana Use cloudwatch_exporter to pull metrics securely Great for EC2 / Lambda / API Gateway visibility Host Grafana in AWS Amplify or Fargate Example Architectures \u0026amp; Pricing 💡 Single-Account / Starter Org (under $25/mo) CloudTrail → S3 + 30-day lifecycle CloudWatch Log group for VPC flow logs (1 env) Metric filters for key events EventBridge + Lambda notifications 🧠 10-Account Org (under $75/mo) Org-level CloudTrail Centralized logging bucket Athena for on-demand queries (partitioned) GuardDuty in key regions 🧰 Hybrid Open Source (under $60/mo) Wazuh on Spot EC2 / Fargate Logs ingested into OpenSearch for 7 days Archived to S3 Glacier after Automation Snippets for Cost-Efficient Alerts 🎯 EventBridge Rule (UnauthorizedOperation) { \u0026#34;source\u0026#34;: [\u0026#34;aws.cloudtrail\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;AWS API Call via CloudTrail\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;errorCode\u0026#34;: [\u0026#34;UnauthorizedOperation\u0026#34;] } } 📏 CloudWatch Metric Filter (Root Login) filter pattern: \u0026#34;$.userIdentity.type = \\\u0026#34;Root\\\u0026#34; \u0026amp;\u0026amp; $.eventName = \\\u0026#34;ConsoleLogin\\\u0026#34;\u0026#34; 🔔 SNS Notification from Lambda import boto3 sns = boto3.client(\u0026#34;sns\u0026#34;) sns.publish( TopicArn=\u0026#34;arn:aws:sns:region:account:topic\u0026#34;, Message=\u0026#34;Root login detected!\u0026#34;, Subject=\u0026#34;Security Alert\u0026#34; ) Common Pitfalls to Avoid Over-collecting VPC flow logs (use sampled mode for dev) Ignoring storage lifecycle → logs build up, cost you Enabling every AWS Config rule → high evaluation cost Too many EventBridge rules → simplify to key patterns Relying on vendor agents for everything Conclusion Security monitoring in AWS doesn’t have to be expensive — it just has to be intentional.\nStart with native tools. Build in automation. Store smart. And grow from there.\nWith this approach, you can:\nStay compliant Detect threats Reduce your cloud bill If this helped you rethink your AWS monitoring setup, consider subscribing to The Hidden Port — where we explore more real-world strategies like this, every week.\nYou may also like:\nIncident Response in AWS + Free PDF Playbook Stop Using IAM Users (And What to Do Instead) 5 Common AWS Security Misconfigurations (And How to Fix Them) ","permalink":"https://thehiddenport.dev/posts/affordable-aws-security-monitoring/","summary":"\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMonitoring in AWS doesn’t have to be expensive. In this guide, we’ll walk through real-world strategies to detect and respond to security events in AWS without blowing your budget — using a mix of native tooling, automation, and open-source solutions.\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"table-of-contents\"\u003eTable of Contents\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#why-aws-monitoring-costs-spiral\"\u003eWhy AWS Monitoring Costs Spiral\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#key-principles-for-cost-effective-monitoring\"\u003eKey Principles for Cost-Effective Monitoring\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#low-cost-native-aws-tools-for-security-monitoring\"\u003eLow-Cost Native AWS Tools for Security Monitoring\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#open-source-solutions-that-complement-aws\"\u003eOpen-Source Solutions That Complement AWS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#example-architectures--pricing\"\u003eExample Architectures \u0026amp; Pricing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#automation-snippets-for-cost-efficient-alerts\"\u003eAutomation Snippets for Cost-Efficient Alerts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#common-pitfalls-to-avoid\"\u003eCommon Pitfalls to Avoid\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#conclusion\"\u003eConclusion\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWhen people talk about security monitoring in AWS, the conversation quickly jumps to expensive SIEM tools or overengineered pipelines. But if you\u0026rsquo;re running lean, or just want better control over where your money is going, you can achieve excellent security visibility with \u003cstrong\u003esurprisingly low cost\u003c/strong\u003e.\u003c/p\u003e","title":"AWS Security Monitoring: Affordable Tools \u0026 Best Practices"},{"content":"Temporary credentials are one of the most powerful — and misunderstood — access mechanisms in AWS. They’re essential for enabling short-lived, tightly scoped access without the long-term baggage of static IAM user credentials. But with this flexibility comes a new surface for mistakes, misuse, and oversights.\nIn this post, I’ll walk through the core use cases for temporary credentials, how they work, where they go wrong, and the best ways to keep them secure in your environment.\nWhat Are Temporary Credentials, Really? AWS uses temporary credentials via the Security Token Service (STS) to grant access to resources for a limited duration. These credentials are usually assumed via IAM roles, either directly (e.g., sts:AssumeRole) or through identity federation setups (like AWS IAM Identity Center, formerly SSO).\nThey consist of an access key ID, a secret access key, and a session token — all tied to an expiration time. Once expired, they’re useless.\nCompared to static IAM user keys, this is a huge win: there’s no need to rotate them manually, and there’s less risk of long-term exposure. But only if you manage them correctly.\nWhen Should You Use Temporary Credentials? Temporary credentials make the most sense in scenarios like:\nCross-account access: Letting resources or users in one AWS account access another securely Federated users: Providing temporary AWS access to users authenticated through an external IdP (Google, Okta, Azure AD) Machine access: Giving containers, EC2 instances, and Lambda functions the credentials they need to operate — without hardcoding anything The key principle is this: temporary credentials are disposable. That makes them ideal for anything short-lived or session-based.\nWhere Things Go Wrong For all their advantages, temporary credentials can cause problems if:\nRoles are overly permissive Session durations are maxed out unnecessarily You’re not logging and reviewing their use Developers extract them and re-use them outside their intended context These are common missteps. I’ve seen production credentials with full AdministratorAccess scoped to 12-hour sessions being used in CI/CD pipelines with zero monitoring. That defeats the purpose.\nBest Practices for Securing Temporary Credentials Let’s walk through the most effective ways to keep temp creds from turning into a liability:\nScope Your IAM Roles Carefully Start with least privilege — always. Define roles that include only the permissions required for a specific task, service, or automation. Use condition keys like aws:SourceIp, aws:RequestTag, or aws:PrincipalTag to make them even tighter.\nAvoid using wildcard * actions or resources unless you have an ironclad reason.\nSet Conservative Session Durations Just because STS lets you issue credentials for up to 12 hours doesn’t mean you should. Match the session duration to the activity. For ephemeral workloads (like a GitHub Action), keep it down to 15–30 minutes.\nShorter sessions reduce the time window for abuse if credentials are leaked.\nLog and Monitor Usage with CloudTrail Every STS call — including AssumeRole and GetSessionToken — should be logged in CloudTrail. These logs will tell you:\nWho assumed which role When the session started and ended What actions were taken using the temp credentials Consider layering this with CloudWatch or a SIEM (like Wazuh) to alert on suspicious behavior.\nEnforce MFA for Sensitive Role Assumption If a human user is assuming a role with sensitive permissions (e.g. break-glass access), make sure MFA is required to perform role assumption. You can enforce this via IAM policy conditions.\nPro tip: MFA should be enforced always.\nIt adds friction — but that’s the point.\nUse Automation to Rotate and Invalidate Temporary credentials are naturally short-lived, but if you’re generating them programmatically (via custom scripts or credential vending tools), ensure they’re:\nRevoked or expired after use (you don\u0026rsquo;t need to do this if you tailor TTL for each role) Not stored in shared volumes or persistent config files Generated with limited scopes AWS SDKs handle a lot of this for you automatically if you\u0026rsquo;re using instance profiles or OIDC-based IAM roles for service accounts.\nAdvanced Topics: IAM Roles Anywhere and Federation If you’re extending access to on-prem or external systems, consider IAM Roles Anywhere — which issues temporary credentials to workloads outside of AWS using signed X.509 certs.\nFor workforce-level federation (like connecting Okta to AWS), make sure the trust policy on your roles includes constraints on who can assume them, and ideally matches on StringEquals or StringLike conditions.\nWrap Up Temporary credentials are meant to improve security — not complicate it. But like everything in AWS, it comes down to how they’re implemented.\nIf you stick to short lifespans, minimal permissions, solid monitoring, and tight boundaries, they’ll serve you well.\nIf not, they’ll become just another attack surface.\n","permalink":"https://thehiddenport.dev/posts/aws-temporary-credentials-security/","summary":"\u003cp\u003eTemporary credentials are one of the most powerful — and misunderstood — access mechanisms in AWS. They’re essential for enabling short-lived, tightly scoped access without the long-term baggage of static IAM user credentials. But with this flexibility comes a new surface for mistakes, misuse, and oversights.\u003c/p\u003e\n\u003cp\u003eIn this post, I’ll walk through the core use cases for temporary credentials, how they work, where they go wrong, and the best ways to keep them secure in your environment.\u003c/p\u003e","title":"Securing Temporary Credentials in AWS: Best Practices for Safe Role Usage"},{"content":"AWS Incident Response Playbook Template Incident Response Playbook Overview This template provides a structured outline for detecting, investigating, and responding to security incidents in AWS. It assumes limited team size and leverages AWS-native services.\nTriage Checklist Confirm GuardDuty/Security Hub finding Review AWS Config changes Determine scope of access or compromise Log incident in internal tracking system Check IAM activity via CloudTrail Isolation Actions Isolate instances using security group modifications or move to a quarantine subnet Remove affected users’ permissions temporarily Detach public-facing interfaces or load balancers where applicable Evidence Collection EBS Snapshots Identify attached volumes with describe-instances Create snapshots for each volume Tag with incident ID and timestamp Memory Dump (Linux EC2) Trigger AVML dump via SSM command Store result in versioned, write-only S3 bucket Encrypt at rest with SSE-S3 or KMS Retrieve Instance Metadata Use SSM to run: curl http://169.254.169.254/latest/meta-data/ Save output to secure S3 bucket Include as part of forensic report Cold Storage for Evidence Use S3 Glacier or Deep Archive for long-term storage Apply Object Lock (Governance or Compliance mode) Tag evidence with: Case ID Analyst name Acquisition date Post-Incident Analysis Conduct internal review with involved stakeholders Identify control failures and response delays Determine if playbooks or detections require updates Reporting Template ### Incident Summary - **Case ID:** IR-YYYY-NNN - **Date Detected:** - **Source:** (e.g., GuardDuty, Security Hub, Internal report) - **Initial Scope:** - **Impact Assessment:** - **Responder(s):** ### Timeline | Time (UTC) | Event | | ---------- | ---------------------------- | | 09:12 | GuardDuty alert triggered | | 09:15 | Instance isolated via SSM | ### Root Cause Analysis ### Remediation Actions ### Recommendations ### Lessons Learned Response Log Table Action Taken By Who When (UTC) Signature EC2 snapshot created Alice Morgan 2025-04-30 10:34 A.M. (digital) Final Checks IAM credentials rotated Affected services redeployed / sanitized Findings documented in Security Hub Evidence backed up to S3 Glacier Note: Adapt this playbook to your environment. Test it in advance. Incident response is a skill — rehearse it regularly.\nWant a downloadable version in PDF? 📄 Download the AWS Incident Response Playbook (PDF)\nThis includes triage checklists, evidence handling steps, and a reporting framework for real-world IR.\n","permalink":"https://thehiddenport.dev/posts/aws-ir-playbook-template/","summary":"A downloadable AWS incident response playbook for small teams, including isolation workflows, evidence handling, and post-incident reporting guidance.","title":"AWS Incident Response Playbook Template (Free Download)"},{"content":"Cloud breaches are no longer a question of if — but when. For small teams, this means preparing lightweight yet effective incident response workflows that work in the cloud, with the tools you already have.\nIn this guide, I’ll walk you through a modern approach to Incident Response (IR) in AWS, shaped by experience and battle-tested tactics. A downloadable IR playbook is included at the end.\nWhy Cloud IR Is Different In traditional IR, you usually walk into a server room. In AWS, you don’t have physical access — everything is virtual, API-driven, and ephemeral.\nWhat changes:\nYou can\u0026rsquo;t unplug a cable — so you isolate via automations, SSM, IAM \u0026hellip; Forensic imaging becomes memory dumps and logs. Evidence handling must be automated and secure while ensuring its chain of custody. Phase 1: Preparation \u0026ldquo;The worst time to build an IR plan is when you\u0026rsquo;re under attack.\u0026rdquo;\nIdeally: Use a Dedicated IR Account If your organization allows, the most secure approach is to:\nCreate a dedicated AWS account within your Organization for incident response. Use it to store forensic snapshots, memory dumps, and analysis artifacts. Restrict access to security engineers only. Alternative: Lock Down a Region If managing another account is out of scope:\nChoose an unused region as your IR region. Create strict SCPs that deny access to that region except for IR roles. Use it to store snapshots, launch analysis EC2 instances. This keeps investigation resources separate and auditable without needing another account. Pre-Provision IR Tools Store AVML (for memory dumps) in a private S3 bucket or include it as a binary in your base AMIs. Create a Lambda to trigger AVML remotely using SSM. Use write-once S3 with versioning for evidence. Provision EC2 instance profiles for analysis tooling. Prepare your own forensics AMI. Destroy used forensics instance to ensure a clean environment. Phase 2: Detection \u0026amp; Triage Enable and monitor:\nSecurity Hub and GuardDuty (region-wide detection) AWS Inspector AWS Config for change auditing EventBridge rules for high-severity findings to trigger automatic notifications Ideally you would have a SIEM ingesting your notifications with a curated set of rules Example triage filter:\naws securityhub get-findings \\ --filters WorkflowStatus=NEW SeverityLabel=CRITICAL Send alerts to SNS topics, email, or Slack integrations for immediate triage.\nPhase 3: Isolation Option 1: SSM Isolation (no reboot needed) aws ec2 modify-instance-attribute \\ --instance-id i-12345678 \\ --no-source-dest-check aws ec2 modify-network-interface-attribute \\ --network-interface-id eni-xyz \\ --groups sg-isolated-only Option 2: Detach From Load Balancers Quick way to prevent public exposure without shutting down the instance.\nPro Tip It is recommended to define your isolation process and automate it.\nPhase 4: Evidence Collection Snapshot Disks aws ec2 create-snapshot --volume-id vol-0c0e757e277111f3c \\ --description \u0026#39;IR evidence snapshot\u0026#39; --tag-specifications \\ \u0026#39;ResourceType=snapshot,Tags=[{Key=evidence,Value=true},{Key=investigation,Value=InProgress}]\u0026#39; Copy to your IR region or account.\nCapture Memory (Linux) aws ssm send-command \\ --document-name \u0026#34;AWS-RunShellScript\u0026#34; \\ --targets \u0026#34;Key=instanceIds,Values=i-xxxx\u0026#34; \\ --parameters commands=[\u0026#34;sudo ./avml /tmp/memdump.lime\u0026#34;] Send output to your S3 bucket with versioning enabled.\nPro Tip There is no such thing as too many tags, make sure to tag everything, it will help you in the future with your automations or Audits\nPhase 5: Analysis Mount snapshot volumes in EC2 instances in your IR region:\nUse Plaso, Volatility, or log parsing tools Analyze user activity, binaries, system logs Always mount snapshots read-only.\nPhase 6: Remediation \u0026amp; Lessons Learned Rotate IAM keys, delete old roles if it applies Find root cause and generate new AMI/code fix to prevent from happening again Redeploy infrastructure from clean code if it applies Run a blameless retro Store timeline, findings, and action items securely Every user access and actions must be recorded and documented for future audits (Optional) Long-Term Evidence Storage (Cold, Tamper-Proof) Once analysis is complete, evidence must be retained securely — sometimes for years — depending on your industry, legal requirements, or internal policies.\nWhy It Matters Regulatory requirements (e.g., PCI-DSS, ISO 27001) often mandate retention. You may need to revisit evidence in future investigations. Chain-of-custody must be intact — even if team members change. Best Practice: S3 with Object Lock in Compliance Mode Use an S3 bucket with Object Lock enabled, configured for Compliance mode:\nWORM (Write Once, Read Many): After the retention period is set, no one — not even the root user — can delete or modify the data. Versioning must be enabled. Compliance mode ensures true immutability. aws s3api put-object-lock-configuration --bucket forensic-evidence-storage --object-lock-configuration \u0026#39;{ \u0026#34;ObjectLockEnabled\u0026#34;: \u0026#34;Enabled\u0026#34;, \u0026#34;Rule\u0026#34;: { \u0026#34;DefaultRetention\u0026#34;: { \u0026#34;Mode\u0026#34;: \u0026#34;COMPLIANCE\u0026#34;, \u0026#34;Days\u0026#34;: 365 } } }\u0026#39; Pro Tip: Store a signed hash (SHA-256) of the evidence metadata separately in a ticket or case management system for added integrity validation.\nGlacier Deep Archive After the case is closed and data is rarely accessed:\nYou should consider setting a lifecycle policy to transition older snapshots or S3 objects to Glacier Deep Archive. Keep metadata and hashes in S3 Standard for fast audit access. resource \u0026#34;aws_s3_bucket_lifecycle_configuration\u0026#34; \u0026#34;archive\u0026#34; { bucket = aws_s3_bucket.forensic.id rule { id = \u0026#34;archive-old-evidence\u0026#34; status = \u0026#34;Enabled\u0026#34; transition { days = 30 storage_class = \u0026#34;DEEP_ARCHIVE\u0026#34; } } } This minimizes cost while still preserving a chain-of-custody–friendly trail.\nCheck my own IR Playbook Template 📄 Online IR Playbook template\nIncludes:\nTriage checklist Memory and disk acquisition workflows Region lockdown guide Incident summary format Final Thoughts You don’t need a massive budget to handle incidents well in AWS. With preparation and automation, even small teams can contain breaches quickly and gather clean forensic evidence.\nAdapt this guide, test it regularly, and scale it as your team grows.\n","permalink":"https://thehiddenport.dev/posts/incident-response-aws-guide/","summary":"Learn how to run an effective incident response process in AWS using automation and forensic best practices — without needing a separate IR account.","title":"Incident Response in AWS: A Practical Guide"},{"content":"How I Passed the AWS Certified Security – Specialty (SCS-C02) Exam in 2025 Breaking into cloud security isn\u0026rsquo;t easy — and staying sharp is even harder.\nThis April, I finally earned my AWS Certified Security – Specialty (SCS-C02) certification, and in this post, I want to share exactly how I prepared, what worked, and a few things I wish I knew earlier.\nIf you\u0026rsquo;re aiming for this cert, I hope this helps you navigate the journey more smoothly.\nMy Background Last year I finally became a Cloud Security Engineer after years chasing this position, because of that I knew I needed to deep dive into AWS Security, so this certification became my goal.\nBefore specializing fully in security, I spent several years in DevOps — which gave me a strong foundation in infrastructure, but cloud security demands a very different mindset.\nHow I Studied My study journey was a bit unusual:\nI actually started back in September 2024 by watching Zeal Vora’s course on Udemy and working through the practice exams included.\nHowever, due to a sudden workload spike at my job, I had to put studying on hold until 2025.\nWhen I resumed, I found an amazing recommendation thread on Reddit:\nReddit AWS Certifications Study Resources Thread Special thanks to u/madrasi2021 for his masive threads\nThat thread pointed me towards:\nStephane Maarek’s Security Specialty course (Udemy) — I watched it at 1.5x speed to refresh my memory. It’s only 16 hours, but it\u0026rsquo;s extremely well-structured and easy to digest. Tutorial Dojo’s Practice Exams — by Jon Bonso, legendary in the AWS cert world. Total Study Time All combined — including my earlier September sessions — I estimate I spent about 80–100 hours preparing:\nWatching video lectures Taking practice exams Reading explanations of wrong answers Playing around in AWS (hands-on really helped) Exam Focus Areas While the exam touched almost every domain, I noticed a stronger emphasis on:\nAWS Organizations and multi-account management Fleet management (managing large numbers of resources securely) CloudFront security configurations Oddly, no questions about CloudHSM came up for me.\nPractice Exams Tutorial Dojo’s practice exams were incredibly helpful.\nThey weren’t exact replicas of the real exam questions — but the style, difficulty, and experience were very close to what I faced on exam day.\n✅ I consistently scored 85%+ in both Udemy quizzes and TD practice exams.\n✅ My real exam score was 839, almost perfectly in line with my mocks.\nWhat Helped Me Most The biggest game-changer for me was reading the explanations for every wrong question — not just noting the right answer.\nOver time, this helped me deeply understand:\nSubtle differences between similar services (like Macie vs GuardDuty vs Inspector) How AWS expects you to prioritize security controls (least privilege, defense in depth, managed services when possible) My Advice to Future Candidates If I could give just a few tips, it would be:\nFinish at least one good video course completely (Stephane or Zeal are great) Hammer through practice exams — and focus more on WHY an answer is correct/incorrect than memorizing Track your weak areas and reinforce them aggressively If possible, get hands-on in an AWS account (even if it’s free tier) It’s a technical exam, but it rewards understanding AWS security philosophy, not rote memorization.\nFinal Thoughts The SCS-C02 isn’t easy — but it’s fair.\nAnd more importantly, it teaches you to think like a Cloud Security Engineer, not just a certification chaser.\nIf you’re preparing, stick with it.\nYou’ll come out not just with a certification, but with real skills you can immediately apply.\nGood luck — and see you at The Hidden Port for more cloud security deep dives!\n📩 Stay Tuned I\u0026rsquo;m planning more AWS security, incident response, and hands-on content soon.\nIf you found this helpful, feel free to check out thehiddenport.dev.\n","permalink":"https://thehiddenport.dev/posts/aws-scs-c02-exam-experience/","summary":"My real-world journey passing the AWS Certified Security – Specialty (SCS-C02) exam. Study strategies, mistakes, resources, and tips for future candidates.","title":"How I Passed the AWS Certified Security – Specialty (SCS-C02) Exam in 2025"},{"content":"Why Least Privilege Matters Overly permissive IAM roles are still one of the most exploited weaknesses in AWS. Whether it’s a developer giving s3:* to an app or a CI/CD pipeline allowed to iam:*, misconfigurations create unnecessary attack surface.\nIAM Access Analyzer helps fix that — by showing you what access your policies really grant, and by helping you build tighter permissions from real-world usage data.\nWhat Is IAM Access Analyzer? IAM Access Analyzer is a native AWS feature that helps you:\nIdentify who has access to your AWS resources (trust policies) Analyze what your IAM policies allow (policy analyzer) Generate fine-grained IAM policies based on actual usage It\u0026rsquo;s split into two capabilities:\nFeature Purpose Policy validation \u0026amp; simulation Checks whether your policies are overly broad Access Analyzer (policy generation) Watches IAM role activity and suggests tight-scoped policy JSON Available via console, CLI, SDK, and supported by Terraform\nEnabling IAM Access Analyzer You must have AWS Organizations enabled or a standalone account with IAM Analyzer permissions.\nCLI: aws accessanalyzer create-analyzer --analyzer-name \u0026#34;org-analyzer\u0026#34; --type ORGANIZATION Use --type ACCOUNT if you\u0026rsquo;re not using AWS Organizations.\nTerraform: resource \u0026#34;aws_accessanalyzer_analyzer\u0026#34; \u0026#34;default\u0026#34; { name = \u0026#34;org-analyzer\u0026#34; type = \u0026#34;ORGANIZATION\u0026#34; } Once enabled, it starts monitoring for:\nExternal access grants (e.g., cross-account S3 bucket access, CICD access\u0026hellip;) Overly broad IAM policies Analyzing a Role for Over-Permission Let’s simulate a policy and see if it’s too permissive.\nStep 1: Write the IAM policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } } Step 2: Run a simulation aws iam simulate-custom-policy --policy-input-list file://policy.json --action-names \u0026#34;s3:ListBucket\u0026#34; \u0026#34;ec2:StartInstances\u0026#34; \u0026#34;iam:DeleteUser\u0026#34; You’ll get a result for each action: allowed or explicitDeny.\nGenerating Policies from CloudTrail Activity IAM Access Analyzer can automatically generate least-privilege IAM policies by analyzing your CloudTrail logs. This lets you replace over-permissive policies with ones that reflect actual usage.\nThis requires CloudTrail to be enabled in the account and set to log to an S3 bucket.\nStep-by-Step in AWS Console Go to the IAM Console:\nNavigate to IAM and click on the desired role. Go to “Generate policy based on CloudTrail events”:\nHere you’ll see the \u0026ldquo;Generate Policy\u0026rdquo; button, click it. Fill the form:\nFill the form to meet your criteria. You can choose a time range from the available CloudTrail logs. Choose the CloudTrail trail that has the relevant data. Click on Generate Policy:\nAWS will scan CloudTrail logs and determine which actions were used. Review and download the policy once ready:\nOnce the job completes, you’ll see a generated policy document. You can copy the JSON, edit it if needed, and attach it to the principal directly or via Terraform. 🧠 This process can take a few minutes depending on the volume of logs. The policy reflects only observed usage — consider reviewing manually before attaching.\nPro Tips Always start Access Analyzer before running new workloads (so it can monitor them) Run it again after a few days of usage to refine permissions Use managed policies for standard access, but custom policies for sensitive services like S3, IAM, EC2 Extra Hardening Use these IAM policy techniques to limit blast radius:\nRequire MFA for IAM console sessions { \u0026#34;Condition\u0026#34;: { \u0026#34;BoolIfExists\u0026#34;: {\u0026#34;aws:MultiFactorAuthPresent\u0026#34;: \u0026#34;false\u0026#34;} } } Use Permission Boundaries Permission boundaries are a powerful but often misunderstood feature of IAM.\nA permission boundary is an advanced policy that defines the maximum permissions a role or user can be granted — even if their assigned IAM policy is broader. It acts as a safety net or “guardrail” to prevent privilege escalation or accidental over-permissioning.\nFor example, if a developer tries to attach an AdministratorAccess policy to a role, but a permission boundary restricts actions to s3:* and ec2:Describe*, then only those actions will be allowed — everything else is denied.\nThis is especially useful in environments where:\nDevelopers or CI/CD pipelines create their own roles or policies You\u0026rsquo;re delegating IAM permissions within a sandbox or dev account You want to limit access in automation scenarios without managing every detail To use them effectively:\nDefine a boundary policy that allows a scoped set of actions Attach the boundary to IAM roles during creation Enforce via Infrastructure as Code (like Terraform) to avoid manual missteps Final Thoughts IAM Access Analyzer helps bridge the gap between \u0026ldquo;theory of least privilege\u0026rdquo; and actual policy enforcement. It\u0026rsquo;s not perfect — but when combined with Terraform and CloudTrail, it\u0026rsquo;s one of the best tools to clean up risky roles without slowing down dev teams.\nUse it to:\nSimulate policies before deployment Detect risky cross-account access Generate scoped policies from real CloudTrail usage For a comprehensive overview of securing your AWS environment, refer to our broader AWS security checklist.\nIn a world of too much access, precision wins. IAM Access Analyzer gives you the tools — now go sharpen your policies. 🔐\n","permalink":"https://thehiddenport.dev/posts/iam-access-analyzer-least-privilege/","summary":"Use IAM Access Analyzer to build least-privilege IAM roles in AWS — includes policy generation from CloudTrail, Terraform integration, and AWS best practices.","title":"Building Least-Privilege IAM Roles with IAM Access Analyzer"},{"content":"Why Root Account Usage Should Raise an Alarm In a secure AWS setup, the root user should almost never be used. It has unrestricted access to everything in the account, and actions taken with it can’t be scoped or logged per identity.\nIf your root user performs any API call, it’s almost always worth reviewing.\nWhat We Want to Detect Any API call made by the root user (e.g., CreateUser, StartInstances, etc.) Especially sensitive actions like UpdateAccountPasswordPolicy, CreateAccessKey, or DeleteTrail CloudTrail captures these events, and we can route them into EventBridge to trigger an alert.\nSolution Overview CloudTrail logs all management events EventBridge Rule matches events made by the root user SNS Topic or Lambda Function sends alerts (email, Slack, etc.) Step 1: Enable CloudTrail CloudTrail must be enabled and logging to an S3 bucket in your account.\nMost accounts have a default trail. If not:\nGo to CloudTrail \u0026gt; Trails Create a new multi-region trail Enable management events Step 2: Create an EventBridge Rule for Root User Events In the Console: Go to EventBridge \u0026gt; Rules Click Create rule Name your rule (e.g., DetectRootUserUsage) Choose Event Source: AWS events Under Event pattern, choose Custom pattern and paste: { \u0026#34;detail\u0026#34;: { \u0026#34;userIdentity\u0026#34;: { \u0026#34;type\u0026#34;: [\u0026#34;Root\u0026#34;] } } } Target: Choose SNS topic (or Lambda if you require some formatting text or to write to Slack for example) Step 3: Create SNS Topic and Email Subscription In the Console: Go to SNS \u0026gt; Topics \u0026gt; Create topic Choose Standard, name it root-usage-alerts Create a subscription to this topic (email) Confirm the subscription from your inbox Optional: Send Slack Alert via Lambda If you prefer Slack notifications instead of email:\nCreate a simple Lambda function that posts to Slack using a webhook Set your EventBridge rule target to that Lambda This allows formatting and routing alerts into your team\u0026rsquo;s incident channel.\nHow to Test It Use the AWS root account to perform a benign action (e.g., visit the Billing Dashboard).\nYou should see an alert shortly after in your email or Slack.\nBest Practices Lock away your root credentials in a secure vault (not used for daily access) Enable MFA on root — ideally phishing-resistant (YubiKey, FIDO2) Delete root access keys if they exist Regularly review CloudTrail and GuardDuty findings This all starts with proper access control.\nRead Why IAM Users Are Obsolete in 2025 to modernize your identity model.\nFinal Thoughts If you\u0026rsquo;re detecting root usage in AWS — that\u0026rsquo;s a signal. Either something\u0026rsquo;s misconfigured, or something\u0026rsquo;s wrong. By setting up this detection and alerting pipeline, you can react quickly and minimize risk.\nIn future guides, we\u0026rsquo;ll build on this with incident response workflows and automated remediations.\n","permalink":"https://thehiddenport.dev/posts/detect-root-account-usage/","summary":"Detect and alert on AWS root account usage using CloudTrail, EventBridge, SNS, and optional Slack notifications. Step-by-step setup and Terraform included.","title":"How to Detect AWS Root Account Usage (And Respond to It)"},{"content":"Misconfigurations continue to be the leading cause of cloud breaches. This 2025 checklist covers the most critical AWS security controls you should implement—whether you\u0026rsquo;re running a side project or managing production workloads.\nUse it to review your setup, catch vulnerabilities early, and build security in by default.\n1. Secure the Root Account Enable MFA (preferably a hardware key like YubiKey or FIDO2) Delete root access keys if any exist Use an IAM user or IAM Identity Center for daily admin tasks 2. Block Public S3 Access Enable Block Public Access at the account level Verify bucket-level settings for sensitive workloads Monitor via AWS Config rules or Access Analyzer AWS now enables these protections by default—but older accounts may still be vulnerable.\n3. Apply IAM Best Practices Use IAM Identity Center (SSO) for human access Replace long-term credentials with STS temporary credentials Enforce MFA using IAM policies \u0026#34;Condition\u0026#34;: { \u0026#34;BoolIfExists\u0026#34;: { \u0026#34;aws:MultiFactorAuthPresent\u0026#34;: \u0026#34;true\u0026#34; } } Use tools like IAM Access Analyzer and Policy Simulator to refine access.\nTo delve deeper into IAM permissions, learn how to analyze and reduce excessive IAM permissions.\n4. Enable Logging Everywhere Service Configuration CloudTrail Org-wide, multi-region, logs to S3 and CloudWatch VPC Flow Logs All VPCs, at least to S3 GuardDuty All regions + EKS enabled AWS Config Track all resource types across all regions Set log retention (30–90 days) to avoid unnecessary costs.\n5. Enable Threat Detection Enable GuardDuty (monitors DNS, CloudTrail, network activity) Enable Security Hub for a centralized security view Use AWS Config for continuous assessment and configuration changes logging Set up SNS alerts for critical and high GuardDuty or Security Hub findings.\n6. Harden Network Security Audit Security Groups (block 0.0.0.0/0 on SSH/RDP) Use SSM Session Manager instead of bastion hosts Enable VPC Flow Logs for visibility Use private subnets for internal resources (Advanced) Consider AWS Network Firewall for deeper inspection 7. Monitor Cloud Costs Create AWS Budgets with thresholds for cost spikes Enable Anomaly Detection for new service usage or region activity This helps catch signs of misconfigured resources or potential compromise.\n8. Automate Security and Compliance Use Control Tower for multi-account environments Define custom AWS Config rules with Lambda Consider using AWS Config automatic remediation for certain non-compliant changes Send weekly Security Hub summaries to email or Slack Automation helps maintain standards even as your environment grows.\n9. Perform Monthly Checks Run IAM Credential Reports (or better yet, automate it to detect unused credentials) Review Trusted Advisor free security checks Track Security Hub Score and set improvement targets Use these reports to catch drift and stale resources early.\n10. Stay Current and Keep Improving Review this checklist quarterly Subscribe to AWS Security blog updates Consider running threat detection simulations using GuardDuty Malware Protection Implement Incident Response playbooks to follow in case of incident Want to go deeper on IAM strategy?\nCheck out Why You Should Stop Using IAM Users in AWS — a full guide on modern access control in 2025.\nFinal Thoughts Security isn\u0026rsquo;t just about avoiding breaches—it\u0026rsquo;s about building systems that are resilient by design.\nWhether you\u0026rsquo;re new to AWS or an experienced engineer, this checklist gives you a clear baseline to protect your environment from common mistakes.\nStart with the basics. Stay consistent. Keep leveling up. 🔐\n","permalink":"https://thehiddenport.dev/posts/aws-security-checklist-2025/","summary":"A step-by-step checklist to secure your AWS account in 2025 — includes IAM hardening, S3 lockdown, logging, and budget alerts. Beginner to intermediate friendly.","title":"AWS Security Checklist 2025: Best Practices Guide"},{"content":"IAM users once helped us bootstrap AWS environments, but in 2025 they are outdated and dangerous. This guide breaks down the risks, modern alternatives, and how to migrate securely—step by step.\nWhy IAM Users Are a Problem in 2025 Risk Impact Frequency Long-term credentials #1 cause of cloud breaches 63% of compromises Manual MFA enforcement Inconsistent protection 42% of accounts No centralized lifecycle Orphaned users linger 3.7x more vulnerable Cross-account sprawl Hard to audit/maintain 81% of enterprises Limited visibility Manual key rotation required 57% non-compliant Modern Alternatives to IAM Users 1. IAM Identity Center (Successor to AWS SSO) Best for: Human access to AWS across accounts\nBenefits:\nIntegrates with IdPs like Google, Azure AD, Okta Manages permissions via centralized permission sets Enables SCIM provisioning and audit visibility 2. STS + AssumeRole for Automation Best for: EC2, Lambda, and inter-service communication\nAdvantages:\nCredentials expire automatically Supports external ID and MFA No static secrets to manage aws sts assume-role --role-arn arn:aws:iam::123456789012:role/AutomationAccess --role-session-name \u0026#34;devops-session\u0026#34; 3. OIDC Federation for CI/CD Pipelines Best for: GitHub Actions, GitLab CI, Bitbucket\nAdvantages:\nNo access keys stored in code Tight role scoping per repo/workflow Credentials rotate automatically GitHub Actions Example:\njobs: deploy: permissions: id-token: write contents: read steps: - uses: aws-actions/configure-aws-credentials@v4 with: role-to-assume: arn:aws:iam::123456789012:role/github-actions aws-region: us-east-1 Migration Roadmap Phase 1: Discover Existing IAM Users and Usage Before making changes, you need a clear picture of who’s using what.\nStep 1: Generate a Credential Report This report lists all IAM users in your account, their MFA status, and if they have active access keys.\naws iam generate-credential-report aws iam get-credential-report --query Content --output text | base64 -d \u0026gt; credential-report.csv Review this CSV file to identify:\nUsers without MFA Users with long-standing credentials Unused accounts Step 2: Map Use Cases Group IAM users into categories:\nHuman access → plan migration to Identity Center CI/CD and automation → migrate to STS or OIDC Legacy systems → evaluate and isolate Phase 2: Replacement Replace human IAM users with IAM Identity Center Replace automated access with STS AssumeRole Reconfigure CI/CD pipelines to use OIDC federation Phase 3: Cleanup Make sure that, for all migrated users, there are no remaining credentials\nIf You Must Keep IAM Users\u0026hellip; If you have legacy apps that require IAM users:\nEnforce MFA Rotate access keys automatically Monitor with CloudTrail and GuardDuty Final Thoughts IAM users served their time—but in 2025, they are no longer secure or scalable.\nBy transitioning to Identity Center for users, STS for automation, and OIDC for pipelines, you\u0026rsquo;re moving toward a modern, zero-trust access model that scales with your org.\nLet IAM users rest in peace. Your future is federated. 🔐\n","permalink":"https://thehiddenport.dev/posts/aws-iam-users-alternatives/","summary":"Stop using IAM users in AWS. This guide explains why they\u0026rsquo;re risky and how to migrate to Identity Center, STS, and OIDC-based access — step-by-step.","title":"IAM Users Are Dead: Modern AWS Access Control for 2025"},{"content":"Misconfigurations remain the top cause of cloud security incidents. While AWS has improved defaults over the years, many organizations still leave critical gaps open to attackers.\nThis guide outlines five high-impact AWS security misconfigurations, explains why they matter, and shows how to fix them with both Console and Terraform examples. These are based on real-world findings from security audits in 2024–2025.\n1. Public S3 Buckets Despite stronger AWS defaults, public S3 buckets continue to expose sensitive data.\nWhy It Matters Public objects can be discovered via brute force or Google indexing. Attackers use open buckets for staging malware or stealing PII. How to Fix It AWS Console:\nGo to S3 \u0026gt; Block Public Access settings for this account Enable all four options at the account level. Account level restrictions will override object level restrictions. Terraform:\nresource \u0026#34;aws_s3_account_public_access_block\u0026#34; \u0026#34;global\u0026#34; { block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } Tooling Tip:\nUse Access Analyzer for S3 to identify any buckets with public access.\n2. Overly Permissive IAM Policies Too often, IAM policies grant Action: * or Resource: * access—even for automation or dev roles.\nWant to fix IAM permissions more precisely?\nCheck out Building Least-Privilege IAM Roles with IAM Access Analyzer — with CLI examples and Terraform.\nWhy It Matters Violates least privilege. Increases blast radius of compromised credentials. How to Fix It Audit Existing Policies:\naws iam simulate-custom-policy --policy-input-list file://policy.json --action-names \u0026#34;s3:GetObject\u0026#34; \u0026#34;ec2:TerminateInstances\u0026#34; Use Permission Boundaries or Access Analyzer:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:GetObject\u0026#34;], \u0026#34;Resource\u0026#34;: [\u0026#34;arn:aws:s3:::my-secure-bucket/*\u0026#34;] } ] } Pro Tip:\nUse IAM Access Analyzer to generate least-privilege policies from actual usage.\n3. IAM Users Without MFA (or Still Using IAM Users at All) IAM users should no longer be used for human access in 2025.\nWhy It Matters IAM users with static access keys are easy targets. No central lifecycle management (unlike SSO). What to Do Instead Adopt IAM Identity Center (SSO) with your identity provider. Use STS AssumeRole for temporary access in automation. For legacy systems: Enforce MFA Monitor with AWS Config + CloudTrail Example MFA Enforcement Policy:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;BoolIfExists\u0026#34;: { \u0026#34;aws:MultiFactorAuthPresent\u0026#34;: \u0026#34;false\u0026#34; } } } ] } 4. Security Groups Open to the World Security groups allowing 0.0.0.0/0 on port 22 or 3389 remain common and dangerous.\nWhy It Matters These ports are constantly scanned. Exploits against SSH/RDP services are common. How to Fix It Recommended:\nUse AWS Systems Manager Session Manager for shell access (no open ports required).\n5. Insufficient Logging and Monitoring Logging is essential for investigation, compliance, and threat detection.\nMust-Have Services AWS CloudTrail (multi-region, org-wide) AWS Config Amazon GuardDuty AWS Security Hub By leveraging services like AWS CloudTrail, AWS Config, Amazon GuardDuty, and AWS Security Hub, organizations can establish a comprehensive security framework in AWS. Together, these tools provide detailed visibility into API activity, ensure continuous compliance with best practices, detect threats using intelligent analysis, and centralize security findings for actionable insights. This integrated approach enhances your ability to prevent, detect, and respond to security incidents effectively, while maintaining a strong security posture across your AWS environment.\nCost Tip:\nSet retention on CloudWatch logs to avoid unnecessary spend.\n📄 Need a full checklist to audit your environment?\nRead the AWS Security Checklist 2025 — 10 critical steps, all in one post.\nFinal Thoughts Misconfigurations like these are often easy to fix—but also easy to miss.\nBy tackling these five areas, you significantly reduce the likelihood of breaches, increase visibility, and build a security-first cloud foundation.\nComing up: deeper dives into automation, policy generation, and detection workflows in AWS.\n📄 Handling misconfigurations is one thing. Responding to them fast is another. Check out the AWS Incident Response Playbook →\nCloud security isn\u0026rsquo;t just about avoiding breaches—it\u0026rsquo;s about building resilient, auditable systems. These fixes are a strong start.\n","permalink":"https://thehiddenport.dev/posts/aws-security-misconfigurations-guide/","summary":"Five AWS misconfigurations still causing breaches in 2025 — includes fixes for public S3 buckets, over-permissive IAM, open security groups, and missing monitoring.","title":"5 Critical AWS Security Misconfigurations (2025 Edition) – How to Find \u0026 Fix Them"},{"content":"🔐 Cloud Security \u0026amp; Auditing Prowler AWS security best practices assessment, CIS benchmarks, and more.\nTags: AWS, CLI, Auditing\nCloudsplaining Analyzes IAM policies for privilege escalation and misconfigurations.\nTags: AWS, IAM, CLI\nCartography Security-focused asset mapping using a Neo4j graph database.\nTags: AWS, Graph, Visualization\n⚙️ Infrastructure as Code Security Checkov Static analysis of Terraform, CloudFormation, Kubernetes, and more.\nTags: IaC, Multi-Cloud, Terraform\ntfsec Security scanner for Terraform code.\nTags: Terraform, CLI\nKICS Finds vulnerabilities and compliance issues in IaC across cloud platforms.\nTags: Multi-Cloud, IaC, Scanning\n🧪 Vulnerability Scanning Trivy Scanner for container images, SBOMs, file systems, and Git repos.\nTags: Containers, SBOM, CLI\n🔎 Threat Detection \u0026amp; Analysis Sigma Generic signature format for SIEM systems.\nTags: Detection, SIEM, SOC\n📚 Notable Docs \u0026amp; Frameworks AWS Security Reference Architecture (SRA) Official AWS modular blueprints for securing multi-account environments.\nHave an open-source tool to recommend? Reach out or submit a PR.\n","permalink":"https://thehiddenport.dev/resources/","summary":"Battle-tested tools, references, and learning materials for cloud security and AWS hardening.","title":"Security Resources"}]